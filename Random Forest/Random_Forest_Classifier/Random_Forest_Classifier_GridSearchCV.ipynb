{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem: We are given information about a subset of the Titanic population and asked to build a predictive model that tells us whether or not a given passenger survived the shipwreck. We are given 10 basic explanatory variables, including passenger gender, age, and price of fare, among others. This is a classic binary classification problem, and we will be implementing a random forest classifer.\n",
    "\n",
    "#### Data: Kaggle - Titanic: Machine Learning from Disaster https://www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a huge difference between classifiers and regressors. Classifiers predict one class from a predetermined list or probabilities of belonging to a class. Regressors predict some value, which could be almost anything.\n",
    "Different metrics are used for classification and regression.\n",
    "#### Difference between a Classifier and a Regressor.\n",
    "A <b>Classifier</b> is used to predict a set of specified labels - The simplest( and most hackneyed) example being that of Email Spam Detection where we will always want to classify whether an email is either spam (1) or not spam(0) .  So each email will get either a 0 or 1 or maybe even a fraction(if you go ahead and decide to predict the probability of an email being spam. \n",
    "<br />\n",
    "Examples : Classifying movie reviews based on text, Detecting the presence of seizures from recorded EEG signals, Classifying whether a passenger would survive in the Titanic disaster.\n",
    "<br /><br />\n",
    "On the other hand a <b>Regressor</b> is used to predict real valued outputs which vary and dont require outputs predicted to be in a fixed set. For example when wanting to predict the future income of restaurants, we really dont know all the possible outputs.\n",
    "<br />\n",
    "Examples : Predicting future Elo ratings of Chess players, Predicting the runs scored by a team in a cricket match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Inspections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Cabin</td>\n",
       "      <td>687</td>\n",
       "      <td>77.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Age</td>\n",
       "      <td>177</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Embarked</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Fare</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ticket</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Total     %\n",
       "Cabin       687  77.1\n",
       "Age         177  19.9\n",
       "Embarked      2   0.2\n",
       "Fare          0   0.0\n",
       "Ticket        0   0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = train.isnull().sum().sort_values(ascending=False)\n",
    "percent_1 = train.isnull().sum()/train.isnull().count()*100\n",
    "percent_2 = (round(percent_1, 1)).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\n",
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Embarked feature has only 2 missing values, which can easily be filled. It will be much more tricky, to deal with the 'Age' feature, which has 177 missing values. The 'Cabin' feature needs further investigation, but it looks like that we might want to drop it from the dataset, since 77 % of it are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see that 38% out of the training-set survived the Titanic. We can also see that the passenger ages range from 0.4 to 80. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Survived column is already binary format. Name, Sex, Ticket, Cabin,and Embarked need further adaptation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.616162\n",
       "1    0.383838\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that 62% of the people in the training set died. This is slightly less than the estimated 67% that died in the actual shipwreck (1500/2224)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass\n",
       "1    0.629630\n",
       "2    0.472826\n",
       "3    0.242363\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].groupby(train['Pclass']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class played a critical role in survival, the survival rate decreased drastically for the lowest class. This variable is both useful and clean, and is categorical variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name & Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Name column as provided cannot be used in the model. However, we might be able to extract some meaningful information from it. First, we can obtain useful information about the passenger's title. Looking at the distribution of the titles, it might be useful to group the smaller sized values into an 'other' group, but this example we don't do it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr.          517\n",
       "Miss.        182\n",
       "Mrs.         125\n",
       "Master.       40\n",
       "Dr.            7\n",
       "Rev.           6\n",
       "Mlle.          2\n",
       "Major.         2\n",
       "Col.           2\n",
       "Lady.          1\n",
       "Sir.           1\n",
       "Capt.          1\n",
       "Mme.           1\n",
       "Don.           1\n",
       "the            1\n",
       "Jonkheer.      1\n",
       "Ms.            1\n",
       "Name: Name_Title, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Name_Title'] = train['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0])\n",
    "train['Name_Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name_Title\n",
       "Capt.        0.000000\n",
       "Col.         0.500000\n",
       "Don.         0.000000\n",
       "Dr.          0.428571\n",
       "Jonkheer.    0.000000\n",
       "Lady.        1.000000\n",
       "Major.       0.500000\n",
       "Master.      0.575000\n",
       "Miss.        0.697802\n",
       "Mlle.        1.000000\n",
       "Mme.         1.000000\n",
       "Mr.          0.156673\n",
       "Mrs.         0.792000\n",
       "Ms.          1.000000\n",
       "Rev.         0.000000\n",
       "Sir.         1.000000\n",
       "the          1.000000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].groupby(train['Name_Title']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the survival rate appears to be either significantly above or below the average survival rate, this variable should be able to help our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      0.647587\n",
       "female    0.352413\n",
       "Name: Sex, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Sex'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex\n",
       "female    0.742038\n",
       "male      0.188908\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].groupby(train['Sex']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Women and children first,\" goes the famous saying. Thus, we should expect females to have a higher survival rate than males, and indeed that is the case. We expect this variable to be very useful in our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age\n",
       "False    0.406162\n",
       "True     0.293785\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].groupby(train['Age'].isnull()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age\n",
       "(0.419, 19.0]    0.481707\n",
       "(19.0, 25.0]     0.328467\n",
       "(25.0, 31.8]     0.393701\n",
       "(31.8, 41.0]     0.437500\n",
       "(41.0, 80.0]     0.373239\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].groupby(pd.qcut(train['Age'],5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.419, 19.0]    164\n",
       "(31.8, 41.0]     144\n",
       "(41.0, 80.0]     142\n",
       "(19.0, 25.0]     137\n",
       "(25.0, 31.8]     127\n",
       "Name: Age, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(train['Age'],5).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon first glance, the relationship between age and survival appears to be a murky one at best. However, this doesn't mean that the variable will be a bad predictor; at deeper levels of a given decision tree, a more discriminant relationship might open up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SibSp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SibSp\n",
       "0    0.345395\n",
       "1    0.535885\n",
       "2    0.464286\n",
       "3    0.250000\n",
       "4    0.166667\n",
       "5    0.000000\n",
       "8    0.000000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].groupby(train['SibSp']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    608\n",
       "1    209\n",
       "2     28\n",
       "4     18\n",
       "3     16\n",
       "8      7\n",
       "5      5\n",
       "Name: SibSp, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['SibSp'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon first glance, the importance of this variable is not too convincing. The distribution and survival rate between the different categories does not provide much hope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parch\n",
       "0    0.343658\n",
       "1    0.550847\n",
       "2    0.500000\n",
       "3    0.600000\n",
       "4    0.000000\n",
       "5    0.200000\n",
       "6    0.000000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].groupby(train['Parch']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    678\n",
       "1    118\n",
       "2     80\n",
       "5      5\n",
       "3      5\n",
       "4      4\n",
       "6      1\n",
       "Name: Parch, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Parch'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "passengers with zero parents or children had a lower likelihood of survival than otherwise, but that survival rate was only slightly less than the overall population survival rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have two seemingly weak predictors, one thing we can do is combine them to get a stronger predictor. In the case of SibSp and Parch, we can combine the two variables to get a 'family size' metric, which might (and in fact does) prove to be a better predictor than the two original variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ticket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Ticket column seems to contain unique alphanumeric values, and is thus not very useful on its own. However, we might be able to extract come predictive power from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           A/5 21171\n",
       "1            PC 17599\n",
       "2    STON/O2. 3101282\n",
       "3              113803\n",
       "4              373450\n",
       "5              330877\n",
       "6               17463\n",
       "7              349909\n",
       "8              347742\n",
       "9              237736\n",
       "Name: Ticket, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Ticket'].head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One piece of potentially useful informatin is the number of characters in the Ticket column. This could be a reflection of the 'type' of ticket a given passenger had, which could somehow indicate their chances of survival. One theory (which may in fact be verifiable) is that some characteristic of the ticket could indicate the location of the passenger's room, which might be a crucial factor in their escape route, and consequently their survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Ticket_Len'] = train['Ticket'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     419\n",
       "5     131\n",
       "4     101\n",
       "8      76\n",
       "10     41\n",
       "7      27\n",
       "9      26\n",
       "17     14\n",
       "16     11\n",
       "13     10\n",
       "12     10\n",
       "15      9\n",
       "11      8\n",
       "18      6\n",
       "3       2\n",
       "Name: Ticket_Len, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Ticket_Len'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another piece of information is the first letter of each ticket, which, again, might be indicative of a certain attribute of the ticketholders or their rooms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Ticket_Letter'] = train['Ticket'].apply(lambda x: str(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    301\n",
       "2    183\n",
       "1    146\n",
       "S     65\n",
       "P     65\n",
       "C     47\n",
       "A     29\n",
       "W     13\n",
       "4     10\n",
       "7      9\n",
       "F      7\n",
       "6      6\n",
       "L      4\n",
       "5      3\n",
       "8      2\n",
       "9      1\n",
       "Name: Ticket_Letter, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Ticket_Letter'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ticket_Letter\n",
       "1    0.630137\n",
       "2    0.464481\n",
       "3    0.239203\n",
       "4    0.200000\n",
       "5    0.000000\n",
       "6    0.166667\n",
       "7    0.111111\n",
       "8    0.000000\n",
       "9    1.000000\n",
       "A    0.068966\n",
       "C    0.340426\n",
       "F    0.571429\n",
       "L    0.250000\n",
       "P    0.646154\n",
       "S    0.323077\n",
       "W    0.153846\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['Ticket_Letter'])['Survived'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.001, 8.662]    308\n",
       "(26.0, 512.329]    295\n",
       "(8.662, 26.0]      288\n",
       "Name: Fare, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(train['Fare'], 3).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fare\n",
       "(-0.001, 8.662]    0.198052\n",
       "(8.662, 26.0]      0.402778\n",
       "(26.0, 512.329]    0.559322\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].groupby(pd.qcut(train['Fare'], 3)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a clear relationship between Fare and Survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pclass</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>(-0.001, 7.854]</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>(7.854, 10.5]</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>(10.5, 21.679]</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>(21.679, 39.688]</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>(39.688, 512.329]</td>\n",
       "      <td>146</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pclass               1   2    3\n",
       "Fare                           \n",
       "(-0.001, 7.854]      6   6  167\n",
       "(7.854, 10.5]        0  24  160\n",
       "(10.5, 21.679]       0  80   92\n",
       "(21.679, 39.688]    64  64   52\n",
       "(39.688, 512.329]  146  10   20"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(pd.qcut(train['Fare'], 5), columns=train['Pclass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a clear relationship between Fare and Class too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cabin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This column has the most nulls (almost 700), but we can still extract information from it, like the first letter of each cabin, or the cabin number. The usefulness of this column might be similar to that of the Ticket variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cabin letter\n",
    "\n",
    "We can see that most of the cabin letters are associated with a high survival rate, so this might very well be a useful variable. Because there aren't that many unique values, we won't do any grouping here, even if some of the values have a small count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Cabin_Letter'] = train['Cabin'].apply(lambda x: str(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n    687\n",
       "C     59\n",
       "B     47\n",
       "D     33\n",
       "E     32\n",
       "A     15\n",
       "F     13\n",
       "G      4\n",
       "T      1\n",
       "Name: Cabin_Letter, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Cabin_Letter'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin_Letter\n",
       "A    0.466667\n",
       "B    0.744681\n",
       "C    0.593220\n",
       "D    0.757576\n",
       "E    0.750000\n",
       "F    0.615385\n",
       "G    0.500000\n",
       "T    0.000000\n",
       "n    0.299854\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].groupby(train['Cabin_Letter']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cabin Number\n",
    "\n",
    "Upon first glance, this appears to be useless. Not only do we have ~700 nulls which will be difficult to impute, but the correlation with Survived is almost zero. However, the cabin numbers as a whole do seem to have a high surival rate compared to the population average, so we might want to keep this just in case for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Cabin_num'] = train['Cabin'].apply(lambda x: str(x).split(' ')[-1][1:])\n",
    "train['Cabin_num'].replace('an', np.NaN, inplace = True)\n",
    "train['Cabin_num'] = train['Cabin_num'].apply(lambda x: int(x) if not pd.isnull(x) and x != '' else np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65.667, 148.0]     67\n",
       "(1.999, 28.667]     67\n",
       "(28.667, 65.667]    66\n",
       "Name: Cabin_num, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(train['Cabin_num'],3).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin_num\n",
       "(1.999, 28.667]     0.716418\n",
       "(28.667, 65.667]    0.651515\n",
       "(65.667, 148.0]     0.641791\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].groupby(pd.qcut(train['Cabin_num'], 3)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06384595922789371"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].corr(train['Cabin_num'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embarked\n",
    "Looks like the Cherbourg people had a 20% higher survival rate than the other embarking locations. This is very likely due to the high presence of upper-class passengers from that location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    0.724409\n",
       "C    0.188976\n",
       "Q    0.086614\n",
       "Name: Embarked, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Embarked'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embarked\n",
       "C    0.553571\n",
       "Q    0.389610\n",
       "S    0.336957\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].groupby(train['Embarked']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21cde171688>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train['Embarked'], hue=train['Pclass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having done our cursory exploration of the variables, we now have a pretty good idea of how we want to transform our variables in preparation for our final dataset. We will perform our feature engineering through a series of helper functions that each serve a specific purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first function creates two separate columns: a numeric column indicating the length of a passenger's Name field, and a categorical column that extracts the passenger's title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def names(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Name_Len'] = i['Name'].apply(lambda x: len(x))\n",
    "        i['Name_Title'] = i['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0])\n",
    "        del i['Name']\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we impute the null values of the Age column by filling in the mean value of the passenger's corresponding title and class. This more granular approach to imputation should be more accurate than merely taking the mean age of the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_impute(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Age_Null_Flag'] = i['Age'].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "        data = train.groupby(['Name_Title', 'Pclass'])['Age']\n",
    "        i['Age'] = data.transform(lambda x: x.fillna(x.mean()))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We combine the SibSp and Parch columns into a new variable that indicates family size, and group the family size variable into three categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fam_size(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Fam_Size'] = np.where((i['SibSp']+i['Parch']) == 0 , 'Solo',\n",
    "                           np.where((i['SibSp']+i['Parch']) <= 3,'Nuclear', 'Big'))\n",
    "        del i['SibSp']\n",
    "        del i['Parch']\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Ticket column is used to create two new columns: Ticket_Letter, which indicates the first letter of each ticket (with the smaller-n values being grouped based on survival rate); and Ticket_Len, which indicates the length of the Ticket field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ticket_grouped(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Ticket_Letter'] = i['Ticket'].apply(lambda x: str(x)[0])\n",
    "        i['Ticket_Letter'] = i['Ticket_Letter'].apply(lambda x: str(x))\n",
    "        i['Ticket_Letter'] = np.where((i['Ticket_Letter']).isin(['1', '2', '3', 'S', 'P', 'C', 'A']), i['Ticket_Letter'],\n",
    "                                   np.where((i['Ticket_Letter']).isin(['W', '4', '7', '6', 'L', '5', '8']),\n",
    "                                            'Low_ticket', 'Other_ticket'))\n",
    "        i['Ticket_Len'] = i['Ticket'].apply(lambda x: len(x))\n",
    "        del i['Ticket']\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two functions extract the first letter of the Cabin column and its number, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cabin(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Cabin_Letter'] = i['Cabin'].apply(lambda x: str(x)[0])\n",
    "        del i['Cabin']\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cabin_num(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Cabin_num1'] = i['Cabin'].apply(lambda x: str(x).split(' ')[-1][1:])\n",
    "        i['Cabin_num1'].replace('an', np.NaN, inplace = True)\n",
    "        i['Cabin_num1'] = i['Cabin_num1'].apply(lambda x: int(x) if not pd.isnull(x) and x != '' else np.NaN)\n",
    "        i['Cabin_num'] = pd.qcut(train['Cabin_num1'],3)\n",
    "    train = pd.concat((train, pd.get_dummies(train['Cabin_num'], prefix = 'Cabin_num')), axis = 1)\n",
    "    test = pd.concat((test, pd.get_dummies(test['Cabin_num'], prefix = 'Cabin_num')), axis = 1)\n",
    "    del train['Cabin_num']\n",
    "    del test['Cabin_num']\n",
    "    del train['Cabin_num1']\n",
    "    del test['Cabin_num1']\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fill the null values in the Embarked column with the most commonly occuring value, which is 'S.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embarked_impute(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Embarked'] = i['Embarked'].fillna('S')\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also fill in the one missing value of Fare in our test set with the mean value of Fare from the training set (transformations of test set data must always be fit using training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Fare'].fillna(train['Fare'].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, because we are using scikit-learn, we must convert our categorical columns into dummy variables. The following function does this, and then it drops the original categorical columns. It also makes sure that each category is present in both the training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummies(train, test, columns = ['Pclass', 'Sex', 'Embarked', 'Ticket_Lett', 'Cabin_Letter', 'Name_Title', 'Fam_Size']):\n",
    "    for column in columns:\n",
    "        train[column] = train[column].apply(lambda x: str(x))\n",
    "        test[column] = test[column].apply(lambda x: str(x))\n",
    "        good_cols = [column+'_'+i for i in train[column].unique() if i in test[column].unique()]\n",
    "        train = pd.concat((train, pd.get_dummies(train[column], prefix = column)[good_cols]), axis = 1)\n",
    "        test = pd.concat((test, pd.get_dummies(test[column], prefix = column)[good_cols]), axis = 1)\n",
    "        del train[column]\n",
    "        del test[column]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our last helper function drops any columns that haven't already been dropped. In our case, we only need to drop the PassengerId column, which we have decided is not useful for our problem (by the way, I've confirmed this with a separate test). Note that dropping the PassengerId column here means that we'll have to load it later when creating our submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop(train, test, bye = ['PassengerId']):\n",
    "    for i in [train, test]:\n",
    "        for z in bye:\n",
    "            del i[z]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having built our helper functions, we can now execute them in order to build our dataset that will be used in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train, test = names(train, test)\n",
    "train, test = age_impute(train, test)\n",
    "train, test = cabin_num(train, test)\n",
    "train, test = cabin(train, test)\n",
    "train, test = embarked_impute(train, test)\n",
    "train, test = fam_size(train, test)\n",
    "test['Fare'].fillna(train['Fare'].mean(), inplace = True)\n",
    "train, test = ticket_grouped(train, test)\n",
    "train, test = dummies(train, test, columns = ['Pclass', 'Sex', 'Embarked', 'Ticket_Letter',\n",
    "                                                                     'Cabin_Letter', 'Name_Title', 'Fam_Size'])\n",
    "train, test = drop(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "print(len(train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our final dataset has 45 columns, composed of our target column and 44 predictor variables. Although highly dimensional datasets can result in high variance but let's see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name_Len</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_num_(1.999, 28.667]</th>\n",
       "      <th>Cabin_num_(28.667, 65.667]</th>\n",
       "      <th>Cabin_num_(65.667, 148.0]</th>\n",
       "      <th>Ticket_Len</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>...</th>\n",
       "      <th>Name_Title_Mrs.</th>\n",
       "      <th>Name_Title_Miss.</th>\n",
       "      <th>Name_Title_Master.</th>\n",
       "      <th>Name_Title_Rev.</th>\n",
       "      <th>Name_Title_Dr.</th>\n",
       "      <th>Name_Title_Ms.</th>\n",
       "      <th>Name_Title_Col.</th>\n",
       "      <th>Fam_Size_Nuclear</th>\n",
       "      <th>Fam_Size_Solo</th>\n",
       "      <th>Fam_Size_Big</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived   Age     Fare  Name_Len  Age_Null_Flag  \\\n",
       "0         0  22.0   7.2500        23              0   \n",
       "1         1  38.0  71.2833        51              0   \n",
       "2         1  26.0   7.9250        22              0   \n",
       "3         1  35.0  53.1000        44              0   \n",
       "4         0  35.0   8.0500        24              0   \n",
       "\n",
       "   Cabin_num_(1.999, 28.667]  Cabin_num_(28.667, 65.667]  \\\n",
       "0                          0                           0   \n",
       "1                          0                           0   \n",
       "2                          0                           0   \n",
       "3                          0                           0   \n",
       "4                          0                           0   \n",
       "\n",
       "   Cabin_num_(65.667, 148.0]  Ticket_Len  Pclass_3  ...  Name_Title_Mrs.  \\\n",
       "0                          0           9         1  ...                0   \n",
       "1                          1           8         0  ...                1   \n",
       "2                          0          16         1  ...                0   \n",
       "3                          1           6         0  ...                1   \n",
       "4                          0           6         1  ...                0   \n",
       "\n",
       "   Name_Title_Miss.  Name_Title_Master.  Name_Title_Rev.  Name_Title_Dr.  \\\n",
       "0                 0                   0                0               0   \n",
       "1                 0                   0                0               0   \n",
       "2                 1                   0                0               0   \n",
       "3                 0                   0                0               0   \n",
       "4                 0                   0                0               0   \n",
       "\n",
       "   Name_Title_Ms.  Name_Title_Col.  Fam_Size_Nuclear  Fam_Size_Solo  \\\n",
       "0               0                0                 1              0   \n",
       "1               0                0                 1              0   \n",
       "2               0                0                 0              1   \n",
       "3               0                0                 1              0   \n",
       "4               0                0                 0              1   \n",
       "\n",
       "   Fam_Size_Big  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/grid_search.html\n",
    "<br />\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "<br />\n",
    "<br />\n",
    "We will use grid search to identify the optimal parameters of our random forest model. Because our training dataset is quite small, we can get away with testing a wider range of hyperparameter values. \n",
    "<br />\n",
    "<br />\n",
    "https://stackoverflow.com/questions/19335165/what-is-the-difference-between-cross-validation-and-grid-search\n",
    "<br />\n",
    "<br />\n",
    "Grid search is a method to perform hyper-parameter optimisation, that is, it is a method to find the best combination of hyper-parameters (an example of an hyper-parameter is the learning rate of the optimiser), for a given model (e.g. a CNN) and test dataset. In this scenario, you have several models, each with a different combination of hyper-parameters. Each of these combinations of parameters, which correspond to a single model, can be said to lie on a point of a \"grid\". The goal is then to train each of these models and evaluate them e.g. using cross-validation. You then select the one that performed best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8383838383838383\n",
      "{'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 700}\n",
      "{'mean_fit_time': array([0.17648959, 0.21313572, 1.04943689, 1.92896922, 3.27158356,\n",
      "       0.30650298, 0.37313422, 0.99946666, 1.6491189 , 3.22827466,\n",
      "       0.23654707, 0.48973823, 0.91284553, 1.70575428, 2.59861096,\n",
      "       0.16324647, 0.46974897, 1.38259411, 1.79903849, 2.64525286,\n",
      "       0.17324098, 0.27318788, 1.07609932, 2.13885729, 2.67856868,\n",
      "       0.16324949, 0.30983289, 0.86287252, 1.66910791, 2.88845515,\n",
      "       0.29983958, 0.30317934, 0.9961338 , 1.58581956, 2.82182423,\n",
      "       0.15991418, 0.44310053, 1.05277054, 1.75905935, 2.48200703,\n",
      "       0.15991426, 0.35980781, 1.19935966, 2.00559489, 2.65191428,\n",
      "       0.2132206 , 0.25986171, 0.98589102, 2.19573832, 3.16175405,\n",
      "       0.299143  , 0.36553669, 1.05442095, 1.93540247, 3.35510977,\n",
      "       0.39990934, 0.25986298, 0.87286623, 1.68909566, 2.61193705,\n",
      "       0.18989881, 0.54304345, 1.24266903, 1.90313601, 2.4803133 ,\n",
      "       0.16657853, 0.36313717, 1.15364234, 2.31437453, 2.79900185,\n",
      "       0.1671319 , 0.31649669, 1.15931455, 1.85603571, 2.89906049,\n",
      "       0.23981794, 0.35471789, 1.12273312, 2.09887664, 3.25706776,\n",
      "       0.35047324, 0.32316073, 1.05610164, 1.9589537 , 3.11548773,\n",
      "       0.16324663, 0.49307036, 1.14572326, 2.02815628, 2.93474571,\n",
      "       0.15978678, 0.48468526, 1.12255685, 2.04538449, 3.00423503,\n",
      "       0.15991529, 0.41341217, 1.25384911, 1.9752659 , 2.77851486,\n",
      "       0.2298762 , 0.37979722, 1.0494407 , 2.03890936, 2.89301689,\n",
      "       0.25804965, 0.27318724, 0.99306695, 1.95109073, 3.25087674,\n",
      "       0.23188877, 0.35980709, 1.0161248 , 1.45588851, 3.0650239 ,\n",
      "       0.28984507, 0.2865142 , 1.07609129, 1.71908132, 2.84516096,\n",
      "       0.18323612, 0.54304274, 1.08942509, 1.78571153, 2.70855165,\n",
      "       0.16657782, 0.29983926, 1.23267595, 1.93896198, 2.55529261,\n",
      "       0.15991537, 0.29317713, 1.07942454, 1.96228417, 2.65857879,\n",
      "       0.1932296 , 0.29984029, 0.96948139, 1.71574354, 2.94176006,\n",
      "       0.3164986 , 0.37979635, 0.98947152, 1.69576025, 2.77185965,\n",
      "       0.20654798, 0.56969508, 1.00258366, 1.64774537, 2.35540843]), 'std_fit_time': array([9.30973307e-03, 2.04355252e-02, 5.71255755e-02, 1.62598418e-01,\n",
      "       9.42315867e-02, 1.42596764e-01, 6.01523943e-02, 5.71256728e-02,\n",
      "       7.34452019e-02, 3.60454610e-01, 7.03494815e-02, 1.75594130e-01,\n",
      "       7.40477725e-02, 2.49710637e-01, 2.33256599e-01, 4.71145571e-03,\n",
      "       1.41581847e-01, 5.90354920e-02, 1.74453364e-01, 9.45828546e-02,\n",
      "       4.71196147e-03, 1.88463848e-02, 1.43754702e-01, 6.67972216e-02,\n",
      "       5.23552617e-01, 4.70965976e-03, 6.47736467e-02, 4.10747691e-02,\n",
      "       1.55694395e-01, 1.26686564e-01, 2.15906024e-02, 1.88572868e-02,\n",
      "       1.69876913e-02, 9.87179204e-02, 2.65356093e-01, 2.24783192e-07,\n",
      "       1.03326985e-01, 5.55480539e-02, 1.47115724e-01, 3.29811132e-02,\n",
      "       6.74349576e-07, 3.73959991e-02, 1.57396467e-01, 8.72600570e-02,\n",
      "       4.00812519e-01, 6.84397197e-02, 3.73969761e-02, 8.38567947e-02,\n",
      "       8.78989473e-03, 2.21186005e-01, 1.93363247e-01, 4.50220836e-02,\n",
      "       3.36239009e-02, 1.35981518e-01, 4.28941665e-01, 8.28298318e-02,\n",
      "       4.96382340e-02, 1.69895928e-02, 1.00280342e-01, 1.77731427e-01,\n",
      "       3.55706659e-02, 1.53178686e-01, 7.75609504e-02, 3.67419739e-02,\n",
      "       1.81230999e-01, 4.71201770e-03, 4.71116349e-02, 1.04116935e-01,\n",
      "       1.00514018e-01, 2.59330222e-01, 1.99448857e-03, 6.59599303e-02,\n",
      "       4.89340085e-03, 8.15699717e-02, 2.68286889e-01, 7.87244926e-02,\n",
      "       5.33596328e-02, 9.38764550e-02, 2.48997468e-01, 3.49406397e-02,\n",
      "       4.40998430e-02, 7.03586518e-02, 1.79779877e-01, 8.28199388e-02,\n",
      "       1.44886684e-01, 4.71151191e-03, 2.21592573e-01, 5.28902664e-02,\n",
      "       8.82675336e-02, 8.16281662e-02, 5.64958839e-03, 6.06973741e-02,\n",
      "       5.89540119e-02, 1.30573801e-01, 3.92702387e-01, 4.05233662e-07,\n",
      "       5.82924438e-02, 9.81354480e-02, 2.21972753e-01, 7.86977036e-02,\n",
      "       4.54363676e-02, 7.25327381e-02, 1.60747186e-01, 6.47717705e-02,\n",
      "       1.91208629e-01, 1.18219131e-01, 2.86584722e-02, 6.26104339e-02,\n",
      "       1.62991066e-01, 1.52417324e-01, 7.65878220e-02, 7.34452993e-02,\n",
      "       4.71160181e-02, 3.29810891e-02, 3.55736740e-01, 4.96383460e-02,\n",
      "       2.86581951e-02, 1.24658074e-02, 1.56333412e-01, 3.29910370e-02,\n",
      "       3.29805833e-02, 6.94034470e-02, 1.63819372e-01, 8.05101928e-02,\n",
      "       3.18681606e-01, 4.71134332e-03, 8.16028610e-03, 4.18787179e-02,\n",
      "       1.48469324e-01, 1.34167594e-01, 1.12391596e-07, 1.24659986e-02,\n",
      "       1.76729439e-01, 1.11397101e-01, 4.45257379e-01, 3.39754137e-02,\n",
      "       2.94238953e-02, 5.71246995e-02, 1.36882747e-01, 2.02595808e-01,\n",
      "       4.71158496e-02, 1.28252597e-01, 4.54366648e-02, 8.37536107e-02,\n",
      "       4.49517462e-02, 6.59674053e-02, 2.48998562e-01, 2.99276082e-02,\n",
      "       9.22882575e-02, 1.59148123e-01]), 'mean_score_time': array([0.10978111, 0.10994085, 0.11327298, 0.3331542 , 0.33648602,\n",
      "       0.19322983, 0.11660361, 0.11660314, 0.21988169, 0.29983854,\n",
      "       0.15657624, 0.1898973 , 0.12326686, 0.22654581, 0.40977971,\n",
      "       0.11327291, 0.14658705, 0.20655592, 0.22987549, 0.33648602,\n",
      "       0.10994061, 0.11660401, 0.20654837, 0.22654541, 0.29317474,\n",
      "       0.11660043, 0.12326821, 0.11327211, 0.27985072, 0.32316041,\n",
      "       0.22654517, 0.11326472, 0.11660433, 0.2265447 , 0.45309099,\n",
      "       0.10994132, 0.29650497, 0.11327179, 0.21988169, 0.30650234,\n",
      "       0.1099414 , 0.11327259, 0.18656723, 0.22987596, 0.30317132,\n",
      "       0.10993997, 0.11660361, 0.12671542, 0.51993211, 0.32997751,\n",
      "       0.12126176, 0.11558835, 0.14584915, 0.24648372, 0.26652487,\n",
      "       0.19914277, 0.11326989, 0.1099422 , 0.22987684, 0.43976514,\n",
      "       0.11327211, 0.26985486, 0.19989276, 0.34063633, 0.37313326,\n",
      "       0.11660345, 0.14658777, 0.32256905, 0.23302213, 0.42310683,\n",
      "       0.11324167, 0.10994132, 0.11272073, 0.29650704, 0.26682321,\n",
      "       0.1577723 , 0.11327092, 0.23987254, 0.31982819, 0.34911076,\n",
      "       0.22947494, 0.11660449, 0.16990844, 0.22654533, 0.39992428,\n",
      "       0.11327243, 0.18429494, 0.208064  , 0.22769554, 0.36085073,\n",
      "       0.10918705, 0.21704348, 0.10994109, 0.3213582 , 0.3698016 ,\n",
      "       0.11327187, 0.15325061, 0.14717237, 0.22321304, 0.33648554,\n",
      "       0.14325706, 0.11660393, 0.25652766, 0.23320834, 0.33648602,\n",
      "       0.19322983, 0.12326678, 0.11328061, 0.34262745, 0.32316025,\n",
      "       0.13156056, 0.12992962, 0.11993909, 0.22321367, 0.37313342,\n",
      "       0.18323469, 0.14325619, 0.11660361, 0.2298762 , 0.34979765,\n",
      "       0.11993535, 0.13326136, 0.18323398, 0.22654565, 0.40644964,\n",
      "       0.10994093, 0.13992564, 0.16657646, 0.2265451 , 0.35314457,\n",
      "       0.11327211, 0.11327211, 0.14325619, 0.28984475, 0.29650728,\n",
      "       0.11327275, 0.10994077, 0.1166114 , 0.33648554, 0.35647535,\n",
      "       0.18989738, 0.13992508, 0.10994053, 0.2232217 , 0.36647701,\n",
      "       0.19656118, 0.1432569 , 0.11257855, 0.23654048, 0.3331542 ]), 'std_score_time': array([1.13403120e-04, 1.12391596e-07, 4.71128712e-03, 4.71201786e-03,\n",
      "       9.42324859e-03, 1.17788191e-01, 4.71184909e-03, 4.71083767e-03,\n",
      "       8.10467325e-07, 1.06088308e-01, 3.29904176e-02, 1.13077129e-01,\n",
      "       4.71274833e-03, 4.71066896e-03, 4.31814991e-02, 4.71134338e-03,\n",
      "       3.08953125e-02, 1.16079682e-01, 8.15979933e-03, 4.71179290e-03,\n",
      "       4.89903609e-07, 4.71179288e-03, 8.17455314e-02, 4.71089375e-03,\n",
      "       5.18271367e-02, 4.71752486e-03, 1.88458228e-02, 4.71173669e-03,\n",
      "       4.24037757e-02, 6.54543181e-02, 7.58249992e-02, 4.71798570e-03,\n",
      "       4.71184910e-03, 4.71241106e-03, 3.67981203e-02, 7.86741172e-07,\n",
      "       1.37114068e-01, 4.71128714e-03, 2.97360213e-07, 1.08365448e-01,\n",
      "       6.25769923e-07, 4.71207388e-03, 2.86585831e-02, 1.29616312e-06,\n",
      "       5.90337205e-02, 9.60274217e-07, 4.71168049e-03, 2.08591112e-02,\n",
      "       3.19215378e-02, 5.76166031e-03, 1.59416910e-02, 3.62575759e-04,\n",
      "       5.50527433e-02, 3.08231993e-02, 5.24649844e-02, 9.30709660e-02,\n",
      "       4.71111853e-03, 2.19379643e-06, 8.15989675e-03, 7.78471362e-02,\n",
      "       4.71207391e-03, 1.63211560e-02, 1.13371697e-01, 8.11908129e-02,\n",
      "       3.08963666e-02, 4.71224245e-03, 9.42257424e-03, 1.06859266e-01,\n",
      "       2.44808003e-02, 1.24655100e-02, 4.66531913e-03, 1.40826266e-06,\n",
      "       2.70660570e-03, 4.18777189e-02, 5.94556995e-02, 6.90782189e-02,\n",
      "       4.71173691e-03, 5.65387048e-02, 1.41346762e-01, 7.96758992e-02,\n",
      "       8.55106501e-02, 4.71111853e-03, 2.15907128e-02, 9.42083219e-03,\n",
      "       5.64500045e-02, 4.71151190e-03, 5.18398179e-02, 9.28826349e-02,\n",
      "       1.42171862e-02, 3.45692098e-02, 1.88300889e-03, 2.63624042e-02,\n",
      "       2.24783192e-07, 5.61815504e-02, 2.15899770e-02, 4.71123092e-03,\n",
      "       3.39746656e-02, 2.28334643e-02, 4.71111853e-03, 4.71196149e-03,\n",
      "       3.39755540e-02, 4.71173669e-03, 7.12970097e-02, 9.42296761e-03,\n",
      "       4.71213006e-03, 2.05373266e-02, 1.24652764e-02, 4.70590300e-03,\n",
      "       3.96921155e-02, 7.84159829e-02, 3.35239405e-02, 1.63220320e-02,\n",
      "       6.07226737e-06, 4.71050038e-03, 4.71083755e-03, 3.29811132e-02,\n",
      "       4.02553924e-02, 4.71151190e-03, 8.16116203e-03, 8.82708772e-02,\n",
      "       1.41348167e-02, 3.29806395e-02, 8.25401960e-02, 4.71224251e-03,\n",
      "       3.76923762e-02, 4.05233662e-07, 2.94220056e-02, 7.31424026e-02,\n",
      "       4.71151191e-03, 1.69883615e-02, 4.71123093e-03, 4.71072524e-03,\n",
      "       9.42201230e-03, 1.41347043e-02, 5.43359180e-02, 4.71094997e-03,\n",
      "       7.01885292e-07, 4.71685938e-03, 3.85670278e-02, 3.08954240e-02,\n",
      "       8.51992898e-02, 4.24037195e-02, 1.27652315e-06, 4.70534368e-03,\n",
      "       8.98947431e-02, 6.94053315e-02, 1.24656162e-02, 5.27364723e-03,\n",
      "       4.71213006e-03, 4.71218628e-03]), 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_samples_leaf': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_samples_split': masked_array(data=[2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 10, 10, 10, 10, 10, 12,\n",
      "                   12, 12, 12, 12, 16, 16, 16, 16, 16, 2, 2, 2, 2, 2, 4,\n",
      "                   4, 4, 4, 4, 10, 10, 10, 10, 10, 12, 12, 12, 12, 12, 16,\n",
      "                   16, 16, 16, 16, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 10, 10,\n",
      "                   10, 10, 10, 12, 12, 12, 12, 12, 16, 16, 16, 16, 16, 2,\n",
      "                   2, 2, 2, 2, 4, 4, 4, 4, 4, 10, 10, 10, 10, 10, 12, 12,\n",
      "                   12, 12, 12, 16, 16, 16, 16, 16, 2, 2, 2, 2, 2, 4, 4, 4,\n",
      "                   4, 4, 10, 10, 10, 10, 10, 12, 12, 12, 12, 12, 16, 16,\n",
      "                   16, 16, 16, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 10, 10, 10,\n",
      "                   10, 10, 12, 12, 12, 12, 12, 16, 16, 16, 16, 16],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[50, 100, 400, 700, 1000, 50, 100, 400, 700, 1000, 50,\n",
      "                   100, 400, 700, 1000, 50, 100, 400, 700, 1000, 50, 100,\n",
      "                   400, 700, 1000, 50, 100, 400, 700, 1000, 50, 100, 400,\n",
      "                   700, 1000, 50, 100, 400, 700, 1000, 50, 100, 400, 700,\n",
      "                   1000, 50, 100, 400, 700, 1000, 50, 100, 400, 700, 1000,\n",
      "                   50, 100, 400, 700, 1000, 50, 100, 400, 700, 1000, 50,\n",
      "                   100, 400, 700, 1000, 50, 100, 400, 700, 1000, 50, 100,\n",
      "                   400, 700, 1000, 50, 100, 400, 700, 1000, 50, 100, 400,\n",
      "                   700, 1000, 50, 100, 400, 700, 1000, 50, 100, 400, 700,\n",
      "                   1000, 50, 100, 400, 700, 1000, 50, 100, 400, 700, 1000,\n",
      "                   50, 100, 400, 700, 1000, 50, 100, 400, 700, 1000, 50,\n",
      "                   100, 400, 700, 1000, 50, 100, 400, 700, 1000, 50, 100,\n",
      "                   400, 700, 1000, 50, 100, 400, 700, 1000, 50, 100, 400,\n",
      "                   700, 1000, 50, 100, 400, 700, 1000],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 1000}], 'split0_test_score': array([0.80808081, 0.8013468 , 0.80808081, 0.81481481, 0.8047138 ,\n",
      "       0.81818182, 0.83164983, 0.82491582, 0.82491582, 0.82491582,\n",
      "       0.81144781, 0.81144781, 0.80808081, 0.81481481, 0.81818182,\n",
      "       0.80808081, 0.80808081, 0.81144781, 0.8047138 , 0.80808081,\n",
      "       0.81481481, 0.80808081, 0.80808081, 0.80808081, 0.80808081,\n",
      "       0.82154882, 0.81818182, 0.81818182, 0.81818182, 0.81818182,\n",
      "       0.82154882, 0.81818182, 0.81818182, 0.81818182, 0.81818182,\n",
      "       0.82154882, 0.81818182, 0.81818182, 0.81818182, 0.81818182,\n",
      "       0.83164983, 0.82491582, 0.81818182, 0.81818182, 0.81818182,\n",
      "       0.83164983, 0.82828283, 0.81481481, 0.81818182, 0.82154882,\n",
      "       0.81818182, 0.82154882, 0.81144781, 0.81481481, 0.81144781,\n",
      "       0.81818182, 0.82154882, 0.81144781, 0.81481481, 0.81144781,\n",
      "       0.81818182, 0.82154882, 0.81144781, 0.81481481, 0.81144781,\n",
      "       0.81818182, 0.82154882, 0.81144781, 0.81481481, 0.81144781,\n",
      "       0.81818182, 0.82154882, 0.81144781, 0.81481481, 0.81144781,\n",
      "       0.8013468 , 0.80808081, 0.81144781, 0.81144781, 0.80808081,\n",
      "       0.81144781, 0.80808081, 0.82491582, 0.82491582, 0.82491582,\n",
      "       0.80808081, 0.80808081, 0.81144781, 0.81144781, 0.81144781,\n",
      "       0.82828283, 0.81481481, 0.81144781, 0.81481481, 0.81481481,\n",
      "       0.80808081, 0.80808081, 0.81481481, 0.81481481, 0.81144781,\n",
      "       0.80808081, 0.81144781, 0.80808081, 0.81144781, 0.81481481,\n",
      "       0.80808081, 0.81144781, 0.80808081, 0.81144781, 0.81481481,\n",
      "       0.80808081, 0.81144781, 0.80808081, 0.81144781, 0.81481481,\n",
      "       0.81818182, 0.80808081, 0.81144781, 0.81144781, 0.81818182,\n",
      "       0.8047138 , 0.81144781, 0.81144781, 0.81144781, 0.81481481,\n",
      "       0.82828283, 0.82154882, 0.80808081, 0.80808081, 0.80808081,\n",
      "       0.82828283, 0.82154882, 0.80808081, 0.80808081, 0.80808081,\n",
      "       0.82828283, 0.82154882, 0.80808081, 0.80808081, 0.80808081,\n",
      "       0.82828283, 0.82154882, 0.80808081, 0.80808081, 0.80808081,\n",
      "       0.82828283, 0.82154882, 0.80808081, 0.80808081, 0.80808081]), 'split1_test_score': array([0.84511785, 0.85185185, 0.85858586, 0.85521886, 0.85521886,\n",
      "       0.84848485, 0.84175084, 0.85185185, 0.85185185, 0.84848485,\n",
      "       0.85185185, 0.84848485, 0.85521886, 0.85858586, 0.85858586,\n",
      "       0.83164983, 0.83838384, 0.84511785, 0.85185185, 0.85185185,\n",
      "       0.85858586, 0.84511785, 0.83838384, 0.84848485, 0.84511785,\n",
      "       0.82828283, 0.82828283, 0.83838384, 0.83838384, 0.83501684,\n",
      "       0.82828283, 0.82828283, 0.83838384, 0.83838384, 0.83501684,\n",
      "       0.82828283, 0.82828283, 0.83838384, 0.83838384, 0.83501684,\n",
      "       0.83164983, 0.83838384, 0.83164983, 0.84175084, 0.83501684,\n",
      "       0.82828283, 0.83164983, 0.83501684, 0.83501684, 0.83838384,\n",
      "       0.81818182, 0.83501684, 0.83164983, 0.83164983, 0.83164983,\n",
      "       0.81818182, 0.83501684, 0.83164983, 0.83164983, 0.83164983,\n",
      "       0.81818182, 0.83501684, 0.83164983, 0.83164983, 0.83164983,\n",
      "       0.81818182, 0.83501684, 0.83164983, 0.83164983, 0.83164983,\n",
      "       0.81818182, 0.83501684, 0.83164983, 0.83164983, 0.83164983,\n",
      "       0.83838384, 0.84511785, 0.85858586, 0.86195286, 0.86195286,\n",
      "       0.84511785, 0.86195286, 0.84848485, 0.84848485, 0.84848485,\n",
      "       0.84175084, 0.84175084, 0.84511785, 0.84848485, 0.84848485,\n",
      "       0.85185185, 0.85521886, 0.84848485, 0.84848485, 0.85521886,\n",
      "       0.84511785, 0.84848485, 0.84511785, 0.85185185, 0.84511785,\n",
      "       0.83501684, 0.84511785, 0.83501684, 0.83164983, 0.83501684,\n",
      "       0.83501684, 0.84511785, 0.83501684, 0.83164983, 0.83501684,\n",
      "       0.83501684, 0.84511785, 0.83501684, 0.83164983, 0.83501684,\n",
      "       0.82828283, 0.84848485, 0.83838384, 0.83501684, 0.83501684,\n",
      "       0.83501684, 0.84511785, 0.83164983, 0.83838384, 0.83838384,\n",
      "       0.83164983, 0.83164983, 0.83501684, 0.83164983, 0.82828283,\n",
      "       0.83164983, 0.83164983, 0.83501684, 0.83164983, 0.82828283,\n",
      "       0.83164983, 0.83164983, 0.83501684, 0.83164983, 0.82828283,\n",
      "       0.83164983, 0.83164983, 0.83501684, 0.83164983, 0.82828283,\n",
      "       0.83164983, 0.83164983, 0.83501684, 0.83164983, 0.82828283]), 'split2_test_score': array([0.82491582, 0.82828283, 0.83164983, 0.82828283, 0.82491582,\n",
      "       0.84511785, 0.83838384, 0.83164983, 0.83501684, 0.83501684,\n",
      "       0.84175084, 0.84511785, 0.83838384, 0.84175084, 0.83838384,\n",
      "       0.84175084, 0.84511785, 0.84175084, 0.84175084, 0.84175084,\n",
      "       0.82828283, 0.84511785, 0.83838384, 0.83501684, 0.83838384,\n",
      "       0.82154882, 0.82828283, 0.81481481, 0.81481481, 0.82154882,\n",
      "       0.82154882, 0.82828283, 0.81481481, 0.81481481, 0.82154882,\n",
      "       0.82154882, 0.82828283, 0.81481481, 0.81481481, 0.82154882,\n",
      "       0.81818182, 0.81818182, 0.81481481, 0.81481481, 0.81481481,\n",
      "       0.81144781, 0.80808081, 0.81818182, 0.81481481, 0.81818182,\n",
      "       0.82491582, 0.80808081, 0.7979798 , 0.7979798 , 0.7979798 ,\n",
      "       0.82491582, 0.80808081, 0.7979798 , 0.7979798 , 0.7979798 ,\n",
      "       0.82491582, 0.80808081, 0.7979798 , 0.7979798 , 0.7979798 ,\n",
      "       0.82491582, 0.80808081, 0.7979798 , 0.7979798 , 0.7979798 ,\n",
      "       0.82491582, 0.80808081, 0.7979798 , 0.7979798 , 0.7979798 ,\n",
      "       0.83838384, 0.82828283, 0.82828283, 0.82491582, 0.82154882,\n",
      "       0.82828283, 0.83838384, 0.84175084, 0.83501684, 0.83164983,\n",
      "       0.83838384, 0.84511785, 0.83501684, 0.84511785, 0.83838384,\n",
      "       0.83501684, 0.83501684, 0.84175084, 0.84175084, 0.84175084,\n",
      "       0.84175084, 0.85185185, 0.84175084, 0.83838384, 0.83838384,\n",
      "       0.81818182, 0.81818182, 0.81144781, 0.81481481, 0.81818182,\n",
      "       0.81818182, 0.81818182, 0.81144781, 0.81481481, 0.81818182,\n",
      "       0.81818182, 0.81818182, 0.81144781, 0.81481481, 0.81818182,\n",
      "       0.82154882, 0.82491582, 0.82154882, 0.82491582, 0.82491582,\n",
      "       0.83164983, 0.82154882, 0.82828283, 0.82154882, 0.82154882,\n",
      "       0.81818182, 0.8013468 , 0.7979798 , 0.7979798 , 0.7979798 ,\n",
      "       0.81818182, 0.8013468 , 0.7979798 , 0.7979798 , 0.7979798 ,\n",
      "       0.81818182, 0.8013468 , 0.7979798 , 0.7979798 , 0.7979798 ,\n",
      "       0.81818182, 0.8013468 , 0.7979798 , 0.7979798 , 0.7979798 ,\n",
      "       0.81818182, 0.8013468 , 0.7979798 , 0.7979798 , 0.7979798 ]), 'mean_test_score': array([0.82603816, 0.82716049, 0.83277217, 0.83277217, 0.82828283,\n",
      "       0.8372615 , 0.8372615 , 0.83613917, 0.8372615 , 0.83613917,\n",
      "       0.83501684, 0.83501684, 0.8338945 , 0.83838384, 0.83838384,\n",
      "       0.82716049, 0.8305275 , 0.83277217, 0.83277217, 0.8338945 ,\n",
      "       0.8338945 , 0.83277217, 0.82828283, 0.8305275 , 0.8305275 ,\n",
      "       0.82379349, 0.82491582, 0.82379349, 0.82379349, 0.82491582,\n",
      "       0.82379349, 0.82491582, 0.82379349, 0.82379349, 0.82491582,\n",
      "       0.82379349, 0.82491582, 0.82379349, 0.82379349, 0.82491582,\n",
      "       0.82716049, 0.82716049, 0.82154882, 0.82491582, 0.82267116,\n",
      "       0.82379349, 0.82267116, 0.82267116, 0.82267116, 0.82603816,\n",
      "       0.82042649, 0.82154882, 0.81369248, 0.81481481, 0.81369248,\n",
      "       0.82042649, 0.82154882, 0.81369248, 0.81481481, 0.81369248,\n",
      "       0.82042649, 0.82154882, 0.81369248, 0.81481481, 0.81369248,\n",
      "       0.82042649, 0.82154882, 0.81369248, 0.81481481, 0.81369248,\n",
      "       0.82042649, 0.82154882, 0.81369248, 0.81481481, 0.81369248,\n",
      "       0.82603816, 0.82716049, 0.83277217, 0.83277217, 0.8305275 ,\n",
      "       0.82828283, 0.83613917, 0.83838384, 0.83613917, 0.83501684,\n",
      "       0.82940516, 0.83164983, 0.8305275 , 0.83501684, 0.83277217,\n",
      "       0.83838384, 0.83501684, 0.8338945 , 0.83501684, 0.8372615 ,\n",
      "       0.83164983, 0.83613917, 0.8338945 , 0.83501684, 0.83164983,\n",
      "       0.82042649, 0.82491582, 0.81818182, 0.81930415, 0.82267116,\n",
      "       0.82042649, 0.82491582, 0.81818182, 0.81930415, 0.82267116,\n",
      "       0.82042649, 0.82491582, 0.81818182, 0.81930415, 0.82267116,\n",
      "       0.82267116, 0.82716049, 0.82379349, 0.82379349, 0.82603816,\n",
      "       0.82379349, 0.82603816, 0.82379349, 0.82379349, 0.82491582,\n",
      "       0.82603816, 0.81818182, 0.81369248, 0.81257015, 0.81144781,\n",
      "       0.82603816, 0.81818182, 0.81369248, 0.81257015, 0.81144781,\n",
      "       0.82603816, 0.81818182, 0.81369248, 0.81257015, 0.81144781,\n",
      "       0.82603816, 0.81818182, 0.81369248, 0.81257015, 0.81144781,\n",
      "       0.82603816, 0.81818182, 0.81369248, 0.81257015, 0.81144781]), 'std_test_score': array([0.01514112, 0.02063387, 0.02063387, 0.01679756, 0.0207556 ,\n",
      "       0.01356122, 0.00419939, 0.01144561, 0.01111054, 0.00965469,\n",
      "       0.01716842, 0.01672241, 0.01950409, 0.01802736, 0.01649488,\n",
      "       0.01410753, 0.01610853, 0.01514112, 0.02026428, 0.01871305,\n",
      "       0.01830472, 0.01745943, 0.01428499, 0.01679756, 0.01610853,\n",
      "       0.00317444, 0.00476166, 0.0104081 , 0.0104081 , 0.00727356,\n",
      "       0.00317444, 0.00476166, 0.0104081 , 0.0104081 , 0.00727356,\n",
      "       0.00317444, 0.00476166, 0.0104081 , 0.0104081 , 0.00727356,\n",
      "       0.00634888, 0.00839878, 0.00727356, 0.01198325, 0.00883727,\n",
      "       0.00883727, 0.0104081 , 0.00883727, 0.00883727, 0.00883727,\n",
      "       0.00317444, 0.01099659, 0.01383707, 0.01374573, 0.01383707,\n",
      "       0.00317444, 0.01099659, 0.01383707, 0.01374573, 0.01383707,\n",
      "       0.00317444, 0.01099659, 0.01383707, 0.01374573, 0.01383707,\n",
      "       0.00317444, 0.01099659, 0.01383707, 0.01374573, 0.01383707,\n",
      "       0.00317444, 0.01099659, 0.01383707, 0.01374573, 0.01383707,\n",
      "       0.01745943, 0.01514112, 0.01950409, 0.02135387, 0.02289122,\n",
      "       0.01374573, 0.02205037, 0.00991219, 0.00965469, 0.00991219,\n",
      "       0.01514112, 0.01672241, 0.01410753, 0.01672241, 0.01563231,\n",
      "       0.00991219, 0.01649488, 0.01610853, 0.01454712, 0.01679756,\n",
      "       0.01672241, 0.01988782, 0.01356122, 0.0153066 , 0.01454712,\n",
      "       0.01111054, 0.01454712, 0.01198325, 0.00883727, 0.00883727,\n",
      "       0.01111054, 0.01454712, 0.01198325, 0.00883727, 0.00883727,\n",
      "       0.01111054, 0.01454712, 0.01198325, 0.00883727, 0.00883727,\n",
      "       0.00419939, 0.01657107, 0.01111054, 0.00965469, 0.00691853,\n",
      "       0.01356122, 0.01410753, 0.00883727, 0.01111054, 0.00991219,\n",
      "       0.00572281, 0.01259817, 0.01563231, 0.01410753, 0.01259817,\n",
      "       0.00572281, 0.01259817, 0.01563231, 0.01410753, 0.01259817,\n",
      "       0.00572281, 0.01259817, 0.01563231, 0.01410753, 0.01259817,\n",
      "       0.00572281, 0.01259817, 0.01563231, 0.01410753, 0.01259817,\n",
      "       0.00572281, 0.01259817, 0.01563231, 0.01410753, 0.01259817]), 'rank_test_score': array([ 59,  46,  26,  26,  43,   5,   7,   9,   5,   9,  14,  14,  21,\n",
      "         1,   1,  46,  37,  26,  26,  21,  21,  26,  43,  37,  37,  73,\n",
      "        62,  73,  73,  62,  73,  62,  73,  73,  62,  73,  62,  73,  73,\n",
      "        62,  46,  46,  96,  62,  88,  73,  88,  88,  88,  52, 102,  96,\n",
      "       126, 121, 126, 102,  96, 126, 121, 126, 102,  96, 126, 121, 126,\n",
      "       102,  96, 126, 121, 126, 102,  96, 126, 121, 126,  59,  46,  26,\n",
      "        26,  37,  43,  13,   1,   9,  14,  42,  34,  37,  14,  26,   1,\n",
      "        14,  21,  14,   7,  34,   9,  21,  20,  34, 102,  62, 113, 110,\n",
      "        88, 102,  62, 113, 110,  88, 102,  62, 113, 110,  88,  88,  46,\n",
      "        73,  73,  59,  73,  52,  73,  73,  62,  52, 113, 126, 141, 146,\n",
      "        52, 113, 126, 141, 146,  52, 113, 126, 141, 146,  52, 113, 126,\n",
      "       141, 146,  52, 113, 126, 141, 146])}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_features='auto', oob_score=True, random_state=1, n_jobs=-1)\n",
    "\n",
    "param_grid = { \"criterion\" : [\"gini\", \"entropy\"], \"min_samples_leaf\" : [1, 5, 10], \"min_samples_split\" : [2, 4, 10, 12, 16], \"n_estimators\": [50, 100, 400, 700, 1000]}\n",
    "\n",
    "gs = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "\n",
    "grids = gs.fit(train.iloc[:, 1:], train.iloc[:, 0])\n",
    "\n",
    "print(grids.best_score_)\n",
    "print(grids.best_params_)\n",
    "print(grids.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that our optimal parameter settings are not at the endpoints of our provided values, meaning that we do not have to test more values. What else can we say about our optimal values? The min_samples_split parameter is at 10, which should help mitigate overfitting to a certain degree. This is especially good because we have a relatively large number of estimators (700), which could potentially increase our generalization error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Estimation and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8294\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(criterion='gini', \n",
    "                             n_estimators=700,\n",
    "                             min_samples_split=10,\n",
    "                             min_samples_leaf=1,\n",
    "                             max_features='auto',\n",
    "                             oob_score=True,\n",
    "                             random_state=1,\n",
    "                             n_jobs=-1)\n",
    "rf.fit(train.iloc[:, 1:], train.iloc[:, 0])\n",
    "print(\"%.4f\" % rf.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to fit our model using the optimal hyperparameters. The out-of-bag score can give us an unbiased estimate of the model accuracy, and we can see that the score is 82.94%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a brief look at our variable importance according to our random forest model. We can see that some of the original columns we predicted would be important in fact were, including gender, fare, and age. We also see title, name length, and ticket length features are important.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Sex_female</td>\n",
       "      <td>0.111215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Sex_male</td>\n",
       "      <td>0.109769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>Name_Title_Mr.</td>\n",
       "      <td>0.109746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fare</td>\n",
       "      <td>0.088209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Name_Len</td>\n",
       "      <td>0.087904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Age</td>\n",
       "      <td>0.078651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Pclass_3</td>\n",
       "      <td>0.043268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>Name_Title_Miss.</td>\n",
       "      <td>0.031292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Ticket_Len</td>\n",
       "      <td>0.031079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>Name_Title_Mrs.</td>\n",
       "      <td>0.028852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>Cabin_Letter_n</td>\n",
       "      <td>0.027893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>Fam_Size_Big</td>\n",
       "      <td>0.025199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>Fam_Size_Nuclear</td>\n",
       "      <td>0.022704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Pclass_1</td>\n",
       "      <td>0.021810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Ticket_Letter_1</td>\n",
       "      <td>0.017999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Ticket_Letter_3</td>\n",
       "      <td>0.012902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Pclass_2</td>\n",
       "      <td>0.012345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>Name_Title_Master.</td>\n",
       "      <td>0.012098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Ticket_Letter_Low_ticket</td>\n",
       "      <td>0.011723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>0.011546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    variable  importance\n",
       "12                Sex_female    0.111215\n",
       "11                  Sex_male    0.109769\n",
       "33            Name_Title_Mr.    0.109746\n",
       "1                       Fare    0.088209\n",
       "2                   Name_Len    0.087904\n",
       "0                        Age    0.078651\n",
       "8                   Pclass_3    0.043268\n",
       "35          Name_Title_Miss.    0.031292\n",
       "7                 Ticket_Len    0.031079\n",
       "34           Name_Title_Mrs.    0.028852\n",
       "25            Cabin_Letter_n    0.027893\n",
       "43              Fam_Size_Big    0.025199\n",
       "41          Fam_Size_Nuclear    0.022704\n",
       "9                   Pclass_1    0.021810\n",
       "19           Ticket_Letter_1    0.017999\n",
       "20           Ticket_Letter_3    0.012902\n",
       "10                  Pclass_2    0.012345\n",
       "36        Name_Title_Master.    0.012098\n",
       "23  Ticket_Letter_Low_ticket    0.011723\n",
       "13                Embarked_S    0.011546"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((pd.DataFrame(train.iloc[:, 1:].columns, columns = ['variable']), \n",
    "           pd.DataFrame(rf.feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "last step is to predict the target variable for our test data and generate an output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf.predict(test)\n",
    "predictions = pd.DataFrame(predictions, columns=['Survived'])\n",
    "test = pd.read_csv('test.csv')\n",
    "predictions = pd.concat((test.iloc[:, 0], predictions), axis = 1)\n",
    "predictions.to_csv('y_test.csv', sep=\",\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
